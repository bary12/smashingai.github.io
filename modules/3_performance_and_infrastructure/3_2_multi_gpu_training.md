---
title: 3.2 Multi-GPU Training
nav_order: 2
parent: 3. Performance and Infrastructure
---

# Multiple GPUs

Additional resources:

- [DeepSeek V3 Technical Report](https://arxiv.org/abs/2412.19437)
- [OLMo repo](https://github.com/allenai/OLMo)
- [Ultra Scale Playbook](https://huggingface.co/spaces/nanotron/ultrascale-playbook)

{: .key-concepts }
> Data Parallelism, ZeRO, ZeRO++, Fault Tolerance in large training clusters.
